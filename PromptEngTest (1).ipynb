{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3021ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.1-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from openai) (2.11.7)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\exton tech\\miniconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 367.6 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.5/1.0 MB 367.6 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.5/1.0 MB 367.6 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.5/1.0 MB 367.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 326.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 163.8 kB/s eta 0:00:00\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.1-cp313-cp313-win_amd64.whl (203 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, jiter, h11, httpcore, anyio, httpx, openai\n",
      "\n",
      "   ---------------------------------------- 0/7 [sniffio]\n",
      "   ---------------------------------------- 0/7 [sniffio]\n",
      "   ----- ---------------------------------- 1/7 [jiter]\n",
      "   ----- ---------------------------------- 1/7 [jiter]\n",
      "   ----- ---------------------------------- 1/7 [jiter]\n",
      "   ----------- ---------------------------- 2/7 [h11]\n",
      "   ----------- ---------------------------- 2/7 [h11]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ----------------- ---------------------- 3/7 [httpcore]\n",
      "   ---------------------- ----------------- 4/7 [anyio]\n",
      "   ---------------------- ----------------- 4/7 [anyio]\n",
      "   ---------------------- ----------------- 4/7 [anyio]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------------- 7/7 [openai]\n",
      "\n",
      "Successfully installed anyio-4.11.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.11.1 openai-2.6.1 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18320f-df58-4aa9-96d3-7e625edad5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your messages below.\n",
      "Commands: 'bye' to exit | 'save' to save chat | 'summary' for recap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires: openai >= 1.60.0\n",
    "# Run: pip install --upgrade openai\n",
    "\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Use environment variable or direct key safely\n",
    "# Replace with your real key or set it using:\n",
    "#    setx OPENAI_API_KEY \"sk-xxxx\"   (on Windows)\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# System instruction as a string\n",
    "system_prompt = \"You are an intelligent assistant. Reply with 15-50 words.\"\n",
    "\n",
    "# Keep the history as plain text entries\n",
    "history = [f\"System: {system_prompt}\"]\n",
    "\n",
    "print(\"Type your messages below.\\nCommands: 'bye' to exit | 'save' to save chat | 'summary' for recap\\n\")\n",
    "\n",
    "while True:\n",
    "    user_msg = input(\"User: \").strip()\n",
    "    if not user_msg:\n",
    "        continue\n",
    "\n",
    "    if user_msg.lower() == \"bye\":\n",
    "        print(\"GPT-5: Goodbye üëã\")\n",
    "        break\n",
    "\n",
    "    elif user_msg.lower() == \"save\":\n",
    "        with open(\"conversation_history.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(history))\n",
    "        print(\"‚úÖ Conversation saved to conversation_history.txt\\n\")\n",
    "        continue\n",
    "\n",
    "    elif user_msg.lower() == \"summary\":\n",
    "        summary_prompt = \"\\n\".join(history) + \"\\nAssistant: Please summarize our conversation so far.\"\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-5\",\n",
    "                input=summary_prompt,\n",
    "            )\n",
    "            summary = response.output_text.strip()\n",
    "            print(f\"GPT-5 (Summary): {summary}\\n\")\n",
    "            history.append(f\"Assistant (Summary): {summary}\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Error while summarizing:\", e)\n",
    "        continue\n",
    "\n",
    "    # Append user input to history\n",
    "    history.append(f\"User: {user_msg}\")\n",
    "\n",
    "    # Join conversation for model input\n",
    "    prompt = \"\\n\".join(history)\n",
    "\n",
    "    # Retry mechanism for API failures\n",
    "    reply = None\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-5\",\n",
    "                input=prompt,\n",
    "                reasoning={\"effort\": \"medium\"},\n",
    "                text={\"verbosity\": \"medium\"}\n",
    "            )\n",
    "            reply = response.output_text.strip()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error (attempt {attempt+1}):\", e)\n",
    "            if attempt < 2:\n",
    "                print(\"Retrying...\\n\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(\"‚ùå Failed after 3 attempts. Exiting.\")\n",
    "                quit()\n",
    "\n",
    "    if reply:\n",
    "        print(f\"GPT-5: {reply}\\n\")\n",
    "        history.append(f\"Assistant: {reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab176f-cc00-45b7-b505-267a32146101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
